import os
import json
import sqlite3
import requests
from bs4 import BeautifulSoup
from dotenv import load_dotenv
from openai import OpenAI
import urllib.parse

# 1. í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
NAVER_CLIENT_ID = os.getenv("NAVER_CLIENT_ID")
NAVER_CLIENT_SECRET = os.getenv("NAVER_CLIENT_SECRET")

# 2. ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”
def init_db():
    conn = sqlite3.connect("energy_data.db")
    cursor = conn.cursor()
    cursor.execute("""
        CREATE TABLE IF NOT EXISTS projects (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            title TEXT,
            url TEXT UNIQUE,
            project_name TEXT,
            location TEXT,
            power_capacity_mw TEXT,
            energy_tech TEXT,
            pue_target TEXT,
            companies TEXT,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
    """)
    conn.commit()
    return conn

# 3. ë‰´ìŠ¤ ê²€ìƒ‰
def search_news(keyword, display=5):
    encText = urllib.parse.quote(keyword)
    url = f"https://openapi.naver.com/v1/search/news.json?query={encText}&display={display}&sort=date"
    headers = {"X-Naver-Client-Id": NAVER_CLIENT_ID, "X-Naver-Client-Secret": NAVER_CLIENT_SECRET}
    response = requests.get(url, headers=headers)
    return response.json().get('items', []) if response.status_code == 200 else []

# 4. ë³¸ë¬¸ ìŠ¤í¬ë˜í•‘
def scrape_article_body(url):
    try:
        headers = {"User-Agent": "Mozilla/5.0"}
        res = requests.get(url, headers=headers, timeout=5)
        soup = BeautifulSoup(res.text, 'html.parser')
        article = soup.select_one("#newsct_article") or soup.select_one("#articleBodyContents") or soup.select_one("article")
        return article.get_text(strip=True)[:2000] if article else ""
    except:
        return ""

# 5. AI ë¶„ì„
def analyze_with_ai(text):
    print("ğŸ¤– AI ë¶„ì„ ì¤‘...")
    system_prompt = "ë„ˆëŠ” ì—ë„ˆì§€ ì „ë¬¸ ë¶„ì„ê°€ì•¼. ê¸°ì‚¬ ë‚´ìš©ì„ ë¶„ì„í•´ project_name, location, power_capacity_mw, energy_tech, pue_target, companies ì •ë³´ë¥¼ JSONìœ¼ë¡œ ì¶œë ¥í•´. ì •ë³´ê°€ ì—†ìœ¼ë©´ nullë¡œ í‘œì‹œí•´."
    try:
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "system", "content": system_prompt}, {"role": "user", "content": text}],
            response_format={ "type": "json_object" }
        )
        return json.loads(response.choices[0].message.content)
    except:
        return None

# 6. ë©”ì¸ ë¡œì§ (ìˆ˜ì •ë¨)
def main():
    conn = init_db()
    cursor = conn.cursor()
    
    keyword = "ë°ì´í„°ì„¼í„° ì‹ ì¶• ìš©ëŸ‰"
    print(f"ğŸš€ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ì‹œì‘: {keyword}")
    
    news_items = search_news(keyword, display=10)
    
    new_count = 0
    for item in news_items:
        title = item['title'].replace('<b>', '').replace('</b>', '').replace('&quot;', '"')
        link = item['link']
        
        cursor.execute("SELECT id FROM projects WHERE url = ?", (link,))
        if cursor.fetchone():
            continue
        
        print(f"\nâœ¨ ìƒˆ ê¸°ì‚¬ ë°œê²¬: {title}")
        body_text = scrape_article_body(link)
        
        if len(body_text) > 200:
            analysis = analyze_with_ai(body_text)
            if analysis:
                # â­ [ìˆ˜ì • í•µì‹¬] ë¦¬ìŠ¤íŠ¸ í˜•íƒœì˜ ë°ì´í„°ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ëŠ” ì•ˆì „ì¥ì¹˜
                for key in analysis:
                    if isinstance(analysis[key], list):
                        analysis[key] = ", ".join(map(str, analysis[key]))
                
                try:
                    cursor.execute("""
                        INSERT INTO projects (title, url, project_name, location, power_capacity_mw, energy_tech, pue_target, companies)
                        VALUES (?, ?, ?, ?, ?, ?, ?, ?)
                    """, (title, link, analysis.get('project_name'), analysis.get('location'), 
                          analysis.get('power_capacity_mw'), analysis.get('energy_tech'), 
                          analysis.get('pue_target'), analysis.get('companies')))
                    conn.commit()
                    print(f"âœ… ì €ì¥ ì™„ë£Œ: {analysis.get('project_name')}")
                    new_count += 1
                except Exception as db_err:
                    print(f"âŒ DB ì €ì¥ ì˜¤ë¥˜: {db_err}")
        
    print(f"\nğŸ ë¶„ì„ ì¢…ë£Œ. ìƒˆë¡œìš´ í”„ë¡œì íŠ¸ {new_count}ê±´ì„ ë°œê²¬í•˜ì—¬ DBì— ì €ì¥í–ˆìŠµë‹ˆë‹¤.")
    conn.close()

if __name__ == "__main__":
    main()